{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks – Complete 1.5-Hour Workshop\n",
    "Full explanations, examples, equations, and code.\n",
    "Using **f(z)** as the activation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Biological and Artificial Neurons\n",
    "\n",
    "### 1.1 Biological Inspiration\n",
    "Biological neurons:\n",
    "- Receive signals through **dendrites**  \n",
    "- Integrate these signals in the **soma**  \n",
    "- Fire an electrical pulse through the **axon** if a threshold is reached  \n",
    "\n",
    "Early neural network research took inspiration from this, but:\n",
    "\n",
    "**Modern artificial neural networks are purely mathematical models.**\n",
    "They do not attempt to replicate biological processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Artificial Neuron – Single Input\n",
    "\n",
    "We begin with the simplest possible artificial neuron.\n",
    "\n",
    "A neuron with:\n",
    "- One input \\( x \\)\n",
    "- One weight \\( w \\)\n",
    "- One bias \\( b \\)\n",
    "- Activation function \\( f(z) \\)\n",
    "\n",
    "Computes:\n",
    "\n",
    "$$\n",
    "z = wx + b\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = f(z)\n",
    "$$\n",
    "\n",
    "This is the core building block of all neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 0.42\n",
      "a = 0.6034832498647263\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(z):  # sigmoid\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "x = 0.6\n",
    "w = 1.2\n",
    "b = -0.3\n",
    "\n",
    "z = w * x + b\n",
    "a = f(z)\n",
    "\n",
    "print(\"z =\", z)\n",
    "print(\"a =\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Artificial Neuron – Multiple Inputs\n",
    "\n",
    "A neuron with many inputs:\n",
    "\n",
    "$$\n",
    "z = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b\n",
    "$$\n",
    "\n",
    "Vector form:\n",
    "\n",
    "$$\n",
    "z = \\mathbf{w}^T \\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "Activation:\n",
    "\n",
    "$$\n",
    "a = f(z)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tomato Growth Example  \n",
    "A simple, intuitive example to explain how neural networks work.\n",
    "\n",
    "We want to predict whether a **tomato plant will grow successfully**.\n",
    "\n",
    "### Input features:\n",
    "- \\( x_1 \\): soil moisture  \n",
    "- \\( x_2 \\): sunlight hours  \n",
    "- \\( x_3 \\): nutrient level  \n",
    "- \\( x_4 \\): temperature  \n",
    "\n",
    "We define the input vector:\n",
    "\n",
    "$$\n",
    "a^{[0]} = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Single-Neuron Tomato Classifier\n",
    "\n",
    "A simple classifier:\n",
    "\n",
    "$$\n",
    "z = w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 + b\n",
    "$$\n",
    "\n",
    "Output:\n",
    "\n",
    "$$\n",
    "a = f(z)\n",
    "$$\n",
    "\n",
    "Interpretation:\n",
    "- \\( a \\approx 1 \\): tomato will grow well  \n",
    "- \\( a \\approx 0 \\): tomato will not grow well  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Adding a Hidden Layer – Automatic Feature Engineering\n",
    "\n",
    "A hidden layer with 3 neurons:\n",
    "\n",
    "$$\n",
    "z^{[1]} = W^{[1]} a^{[0]} + b^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[1]} = f(z^{[1]})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $W^{[1]}$ is a 3×4 matrix  \n",
    "- $b^{[1]}$ is a 3×1 vector  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Output Layer\n",
    "\n",
    "Using the hidden representation:\n",
    "\n",
    "$$\n",
    "z^{[2]} = W^{[2]} a^{[1]} + b^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = a^{[2]} = f(z^{[2]})\n",
    "$$\n",
    "\n",
    "Interpretation:\n",
    "- \\( \\hat{y} \\approx 1 \\): plant grows well  \n",
    "- \\( \\hat{y} \\approx 0 \\): plant grows poorly  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Network Notation\n",
    "\n",
    "### 3.1 Layer Computation\n",
    "\n",
    "General formula for any layer \\(l\\):\n",
    "\n",
    "$$\n",
    "z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[l]} = f(z^{[l]})\n",
    "$$\n",
    "\n",
    "### 3.2 Neuron-Level Notation\n",
    "\n",
    "Neuron \\( i \\) in layer \\( l \\):\n",
    "\n",
    "$$\n",
    "a^{[l]}_i = f(z^{[l]}_i)\n",
    "$$\n",
    "\n",
    "### 3.3 Binary Prediction Rule\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{cases}\n",
    "1 & a^{[L]} \\ge 0.5 \\\\\n",
    "0 & a^{[L]} < 0.5\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Forward Propagation Example – Digits 0 vs 1\n",
    "\n",
    "We classify handwritten digits (0 or 1) from **8×8 grayscale images**.\n",
    "\n",
    "Flatten each image into a 64-dimensional vector:\n",
    "\n",
    "$$\n",
    "a^{[0]} \\in \\mathbb{R}^{64}\n",
    "$$\n",
    "\n",
    "Network architecture:\n",
    "- Layer 1: 25 neurons  \n",
    "- Layer 2: 15 neurons  \n",
    "- Output: 1 neuron  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Forward Computation\n",
    "\n",
    "Layer 1:\n",
    "\n",
    "$$\n",
    "z^{[1]} = W^{[1]} a^{[0]} + b^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[1]} = f(z^{[1]})\n",
    "$$\n",
    "\n",
    "Layer 2:\n",
    "\n",
    "$$\n",
    "z^{[2]} = W^{[2]} a^{[1]} + b^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[2]} = f(z^{[2]})\n",
    "$$\n",
    "\n",
    "Output:\n",
    "\n",
    "$$\n",
    "z^{[3]} = W^{[3]} a^{[2]} + b^{[3]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(z^{[3]})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network output: [[0.44849096]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "n_input, n1, n2, n_out = 64, 25, 15, 1\n",
    "\n",
    "W1 = np.random.randn(n1, n_input)\n",
    "b1 = np.zeros((n1,1))\n",
    "\n",
    "W2 = np.random.randn(n2, n1)\n",
    "b2 = np.zeros((n2,1))\n",
    "\n",
    "W3 = np.random.randn(n_out, n2)\n",
    "b3 = np.zeros((n_out,1))\n",
    "\n",
    "def forward(x):\n",
    "    a0 = x.reshape(-1,1)\n",
    "    a1 = f(W1 @ a0 + b1)\n",
    "    a2 = f(W2 @ a1 + b2)\n",
    "    a3 = f(W3 @ a2 + b3)\n",
    "    return a3\n",
    "\n",
    "x = np.random.rand(64)\n",
    "print(\"Network output:\", forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Equivalent Neural Network in TensorFlow\n",
    "Here is the same architecture implemented in Keras/TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(25, activation='sigmoid', input_shape=(64,)),\n",
    "    tf.keras.layers.Dense(15, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "x_tf = tf.random.normal((1, 64))\n",
    "y_hat = model(x_tf)\n",
    "\n",
    "print(\"TensorFlow prediction:\", float(y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
